---
title: "R Notebook"
output: html_notebook
---

```{r}
#############
# LIBRARIES #
#############

# Load libraries to analyze data
library(FactoMineR)
library(factoextra)
library(CAinterprTools)
library(dplyr)
library(readr)
library(ClustOfVar)
library(reshape2)
#library(data.table)
#library(PCAmixdata)
library(widyr)
library(tidyr)
library(ggplot2)
library(igraph)
library(ggraph)
library(tidytext)
library(tm)
library(cluster)
library(dendextend)
library(NbClust)
library(BHC)

##############################
# LOAD AND PREPARE DATA SETS #
##############################

# Load in data sets from GitHub
keywords.frame <- read.csv("https://raw.githubusercontent.com/jeremyfprice/litreview/master/data/lit_review-keywords-processed.csv", header = TRUE)
methods.frame <- read.csv("https://raw.githubusercontent.com/jeremyfprice/litreview/master/data/lit_review-data_sources-survey_combined.csv", header = TRUE)

```


```{r}

# Combine frames and merge by the Manuscript ID
overall.frame <- merge(keywords.frame, methods.frame, by.x = "manuscriptID")

# Set row names to the Manuscript IDs
#row.names(overall.frame) <- overall.frame$manuscriptID
#overall.frame$manuscriptID <- NULL

overall.frame <- data.frame(lapply(overall.frame, as.character), stringsAsFactors=FALSE)

# Split the overall data into TPACK and non-TPACK sets for analysis
tpack.frame <- overall.frame[overall.frame$tpack %in% "tpack",]
tpack.frame$tpack <- NULL
non_tpack.frame <- overall.frame[overall.frame$tpack %in% "no_tpack",]
non_tpack.frame$tpack <- NULL

#print(row.names(overall.cluster))

prepare.cluster <- function(data.set){
  for(i in 1:ncol(data.set)){
    data.set[,i][grep("no_", data.set[,i])] <- NA
  }
  data.set <- data.set[,colSums(is.na(data.set))<nrow(data.set)]
  data.set[!is.na(data.set)] <- 1
  data.set[is.na(data.set)] <- 0
  data.set <- data.frame(lapply(data.set, as.numeric), stringsAsFactors=FALSE)
  data.set <- scale(data.set)
  data.set <- t(data.set)
  return(data.set)
}

# Convert dataframe from wide to long format (necessary for working with the data)
overall.frame.long <- melt(overall.frame, id.vars = c("manuscriptID"))

# Remove any empty cells
overall.frame.long <- na.omit(overall.frame.long)

# Convert all data to lower case for easier manipulation
overall.frame.long$value <- tolower(overall.frame.long$value)

# Define and remove stopwords, which will not be used in the analysis.
# These words 
overall.frame.long <- subset(overall.frame.long, !(value %in% c("preservice teachers", "technology integration", 
                                        "computer uses in education", 
                                        "preservice teacher education", 
                                        "technology uses in education", "teacher education", 
                                        "educational technology", "teacher education programs", 
                                        "mixed methods research", "interviews", 
                                        "qualitative research", "information technology", 
                                        "correlation", "statistical analysis", 
                                        "comparative analysis", "online surveys", 
                                        "focus groups", "semi structured interviews", 
                                        "likert scales", "predictor variables", 
                                        "teacher surveys", "surveys", "observation", 
                                        "questionnaires", "student surveys", 
                                        "regression (statistics)", "case studies", 
                                        "pretests posttests", "technological literacy", 
                                        "technology education", "coding", "scores", 
                                        "scoring rubrics", "content analysis", 
                                        "data analysis", "data collection", 
                                        "effect size", "statistical significance", 
                                        "participant observation", "elementary secondary education",
                                        "elementary school teachers", "inservice teacher education")))



# Combine similar descriptors
overall.frame.long$value[grep("attitude", overall.frame.long$value)] <- "attitudes"
overall.frame.long$value[grep("behavior", overall.frame.long$value)] <- "behavior"
overall.frame.long$value[grep("games", overall.frame.long$value)] <- "games"
overall.frame.long$value[grep("knowledge ", overall.frame.long$value)] <- "knowledge"
overall.frame.long$value[grep("science instruction", overall.frame.long$value)] <- "stem education"
overall.frame.long$value[grep("mathematics instruction", overall.frame.long$value)] <- "stem education"
overall.frame.long$value[grep("discussion", overall.frame.long$value)] <- "discussion"
overall.frame.long$value[grep("scaffolding", overall.frame.long$value)] <- "scaffolding"
overall.frame.long$value[grep("constructivism", overall.frame.long$value)] <- "constructivism"
#overall.frame.long$value[grep("lesson plans", overall.frame.long$value)] <- "planning_design"
#overall.frame.long$value[grep("instructional design", overall.frame.long$value)] <- "planning_design"
#overall.frame.long$value[grep("curriculum development", overall.frame.long$value)] <- "planning_design"
#overall.frame.long$value[grep("video technology", overall.frame.long$value)] <- "specific technologies"
#overall.frame.long$value[grep("handheld devices", overall.frame.long$value)] <- "specific technologies"

# Rename "pedagogical content knowledge" to "tpack"
overall.frame.long$value[grep("pedagogical content knowledge", overall.frame.long$value)] <- "tpack"

# Rejected changes
#x_long$value[grep("teaching methods", x_long$value)] <- "methods"
#x_long$value[grep("school teachers", x_long$value)] <- "elementary secondary teachers"
#x_long$value[grep("science teachers", x_long$value)] <- "subject area teachers"
#x_long$value[grep("english teachers", x_long$value)] <- "subject area teachers"
#x_long$value[grep("mathematics teachers", x_long$value)] <- "subject area teachers"

# Look for duplications and remove them
overall.frame.long <- overall.frame.long[ , !(names(overall.frame.long) %in% c("X2","variable"))]
overall.frame.long <- overall.frame.long[!duplicated(overall.frame.long), ]

  for(i in 1:ncol(overall.frame.long)){
    overall.frame.long[,i][grep("no_", overall.frame.long[,i])] <- NA
  }

#overall.cluster <- prepare.cluster(overall.frame)
#tpack.cluster <- prepare.cluster(tpack.frame)
#non_tpack.cluster <- prepare.cluster(non_tpack.frame)

# Conduct a count of descriptors
overall.count <- overall.frame.long %>% 
  group_by(value) %>% 
  count(sort = TRUE)

# Select only the descriptors that appear 4 or more times
# For testing purposes, try 1 to include all descriptors
overall.count.sub <- subset(overall.count, n >= 4)

overall.frame.long.sub <- filter(overall.frame.long, value %in% overall.count.sub$value)




# Determine descriptor pairs
#overall.frame.long.complete <- overall.frame.long[complete.cases(overall.frame.long),]
overall.pairs <- overall.frame.long %>% 
  pairwise_count(value, manuscriptID, sort = TRUE, upper = TRUE)
overall.pairs.sub <- subset(overall.pairs, n >= 4)

descriptors.sub.list <- as.list(unique(overall.pairs.sub$item1))

methods.list <- as.list(colnames(methods.frame))

keep.list <- (append(descriptors.sub.list, methods.list))

#test.frame <- subset(overall.pairs, overall.pairs[1] %in% keep.list)# | overall.pairs[2] %in% keep.list)

test.frame <- na.omit(overall.pairs[overall.pairs[1, ] %in% keep.list, ]) && 
  na.omit(overall.pairs[overall.pairs[2, ] %in% keep.list, ])
test.frame <- subset(overall.pairs, item1 %in% keep.list & item2 %in% keep.list)
test.frame <- test.frame[complete.cases(test.frame), ]
test.frame <- test.frame[!duplicated(test.frame), ]


```

```{r, eval=FALSE, include=FALSE}
#overall.pairs[is.na(overall.pairs)] <- 0

colnames(overall.frame.long)[2] <- "item1"

test1.el <- merge(overall.pairs.el, overall.frame.long, by = "item1")

colnames(overall.frame.long)[2] <- "item2"
colnames(test1.el)[3] <- "manuscript1"

test2.el <- merge(overall.pairs.el, overall.frame.long, by = "item2")

colnames(overall.frame.long)[2] <- "value"
colnames(test2.el)[3] <- "manuscript2"

test.el <- merge(test1.el, test2.el, by = c("item1", "item2"))
test.el$items <- paste(test.el$item1, test.el$item2)
test.el <- test.el[!duplicated(test.el), ]
```

```{r}
overall.pairs.el <- overall.pairs[,1:2]
overall.pairs.el <- overall.pairs.el[!duplicated(overall.pairs), ]

overall.graph <- graph_from_incidence_matrix(overall.pairs, directed = FALSE,
                                                 add.names = NULL)#, weighted = FALSE)

descriptors.pairs.sub <- descriptors.pairs.sub[,1:2]

overall.graph.el <- simplify(graph_from_edgelist(as.matrix(overall.pairs.el),
                                            directed = FALSE))


set.seed(1234)                # for reproducible example

  overall.communities <- cluster_optimal(overall.graph.el, weights = overall.pairs$n)
  print(overall.communities$modularity)


plot.igraph(overall.graph.el,vertex.label=V(overall.graph.el)$name,
            layout=layout.fruchterman.reingold,edge.color="black")#,
            #edge.width=E(descriptors.graph)$weight)

wc <- walktrap.community(overall.graph.el)
fc <- fastgreedy.community(overall.graph.el)
eb <- edge.betweenness.community(overall.graph.el)
V(overall.graph.el)$color <- wc$membership + 1
plot(overall.graph.el)
```


This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Cmd+Shift+Enter*. 

```{r}
cluster.analysis <- function(data.set) {
  # Dissimilarity matrix
 # d <- dist(data.set, method = "euclidean")
  # Hierarchical clustering using Ward's method
  #res.hc <- hclust(d, method = "ward.D2" )
  # Plot the obtained dendrogram
  #plot(res.hc, cex = 0.6, hang = -1)

  # Compute agnes()
  #res.agnes <- agnes(data.set, method = "ward")
  # Agglomerative coefficient
  #res.agnes$ac
  
  # Plot the tree using pltree()
  #pltree(res.agnes, cex = 0.6, hang = -1,
  #       main = "Dendrogram of agnes")
  
  # K-means clustering
  set.seed(123)
  km.res <- kmeans(data.set, 3, nstart = 25)
  # k-means group number of each observation
  km.res$cluster
  plot(km.res)
  set.seed(123)
  # Compute and plot wss for k = 2 to k = 15
  k.max <- 15 # Maximal number of clusters
  data <- data.set
  wss <- sapply(1:k.max, 
                function(k){kmeans(data, k, nstart=10 )$tot.withinss})
  plot(1:k.max, wss,
       type="b", pch = 19, frame = FALSE, 
       xlab="Number of clusters K",
       ylab="Total within-clusters sum of squares")
  abline(v = 3, lty =2)
  
  k.max <- 15
  data <- data.set
  sil <- rep(0, k.max)
  # Compute the average silhouette width for 
  # k = 2 to k = 15
  #for(i in 2:k.max){
  #  km.res <- kmeans(data, centers = i, nstart = 25)
  #  ss <- silhouette(km.res$cluster, dist(data))
  #  sil[i] <- mean(ss[, 3])
  #}
  # Plot the  average silhouette width
  #plot(1:k.max, sil, type = "b", pch = 19, 
  #     frame = FALSE, xlab = "Number of clusters k")
  #cut.data <- 3
  #abline(v = cut.data, lty = 2)

  
  # Cut tree into 10 groups
#  grp <- cutree(res.hc, k = cut.data)
  # Number of members in each cluster
#  print(table(grp))
  
#  for(i in 1:cut.data) {
#    print(rownames(overall.cluster)[grp == i])
#  }
  
#  plot(res.hc, cex = 0.6)
#  rect.hclust(res.hc, k = 3, border = 2:5)
  
  #num.cluster <- fviz_nbclust(data.set, FUNcluster = hcut, method = "silhouette", k.max = 15)
  #print(num.cluster)

  set.seed(123)
  res.nb <- NbClust(data.set, distance = "euclidean",
                    min.nc = 2, max.nc = 15, 
                    method = "complete", index ="gap") 
  print(res.nb) # print the results
  print(fviz_nbclust(res.nb) + theme_minimal())
  # K-means clustering
  set.seed(123)
  km.res <- kmeans(data.set, 3, nstart = 25)
  # k-means group number of each observation
  print(km.res$cluster)
  
  #pam.res <- pam(data.set, 7)
  #print(pam.res$cluster)
  #print(fviz_cluster(pam.res, stand = FALSE, geom = "point",
  #             frame.type = "norm"))
  
  
  #data.labels <- list(row.names(data.set))
  #hc1 <- bhc(data.set, row.names(data.set), verbose=TRUE)
  #plot(hc1, axes = FALSE)
  #print(str(hc1))
}

cluster.analysis(non_tpack.cluster)
#cluster.analysis(tpack.cluster)
#cluster.analysis(overall.cluster)




```

```{r}
library(bclust)
cluster.obj <- bclust(non_tpack.cluster, transformed.par = c(0, -50, log(16), 0, 0, 0),
                      labels = row.names(non_tpack.cluster))
plot(cluster.obj)
abline(h = cluster.obj$cut, lty = 2, col = "gray", lwd = 3)
viplot(imp(cluster.obj)$var)
```


Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Cmd+Option+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Cmd+Shift+K* to preview the HTML file).